{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYFIQkuQtNiGnNahwHc9wH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sachinkumartandon/PRML_project/blob/main/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJJ9XgvPrw3b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and split the data\n",
        "data = pd.read_csv(\"mnist_train_small.csv\")\n",
        "X = data.iloc[:, 1:].values / 255.0  # normalize pixel values\n",
        "y = data.iloc[:, 0].values\n",
        "\n",
        "# One-hot encode labels\n",
        "def one_hot_encode(y, num_classes):\n",
        "    m = y.shape[0]\n",
        "    encoded = np.zeros((m, num_classes))\n",
        "    encoded[np.arange(m), y] = 1\n",
        "    return encoded\n",
        "\n",
        "y_encoded = one_hot_encode(y, num_classes=10)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Parameters\n",
        "m, n = X_train.shape\n",
        "num_classes = 10\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# Initialize weights and bias\n",
        "W = np.random.randn(n, num_classes) * 0.01\n",
        "b = np.zeros((1, num_classes))\n",
        "\n",
        "# Softmax function\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # numerical stability\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "# Loss function (Cross-Entropy)\n",
        "def compute_loss(y_true, y_pred):\n",
        "    m = y_true.shape[0]\n",
        "    log_likelihood = -np.log(y_pred + 1e-15)\n",
        "    loss = np.sum(y_true * log_likelihood) / m\n",
        "    return loss\n",
        "\n",
        "# Training loop with Mini-Batch Gradient Descent\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Shuffle training data\n",
        "    indices = np.random.permutation(m)\n",
        "    X_train_shuffled = X_train[indices]\n",
        "    y_train_shuffled = y_train[indices]\n",
        "\n",
        "    for i in range(0, m, batch_size):\n",
        "        X_batch = X_train_shuffled[i:i+batch_size]\n",
        "        y_batch = y_train_shuffled[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        logits = np.dot(X_batch, W) + b\n",
        "        probs = softmax(logits)\n",
        "\n",
        "        # Compute gradients\n",
        "        error = probs - y_batch\n",
        "        dW = np.dot(X_batch.T, error) / batch_size\n",
        "        db = np.sum(error, axis=0, keepdims=True) / batch_size\n",
        "\n",
        "        # Update parameters\n",
        "        W -= learning_rate * dW\n",
        "        b -= learning_rate * db\n",
        "\n",
        "    # Compute loss for tracking\n",
        "    train_logits = np.dot(X_train, W) + b\n",
        "    train_probs = softmax(train_logits)\n",
        "    loss = compute_loss(y_train, train_probs)\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "def predict(X):\n",
        "    logits = np.dot(X, W) + b\n",
        "    probs = softmax(logits)\n",
        "    return np.argmax(probs, axis=1)\n",
        "\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "y_pred = predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred)\n",
        "print(f\"\\nâœ… Training Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# # Plot loss\n",
        "# plt.plot(loss_history)\n",
        "# plt.xlabel(\"Epoch\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.title(\"Training Loss over Epochs\")\n",
        "# plt.grid()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load the new test data ---\n",
        "import pandas as pd\n",
        "test_data = pd.read_csv(\"mnist_test (1).csv\")\n",
        "X_real_test = test_data.iloc[:, 1:].values / 255.0  # normalize\n",
        "y_real_test = test_data.iloc[:, 0].values\n",
        "\n",
        "# Predict on the test set\n",
        "y_real_pred = predict(X_real_test)\n",
        "\n",
        "# Accuracy\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "acc = accuracy_score(y_real_test, y_real_pred)\n",
        "print(f\"\\nðŸ§ª Final Test Accuracy on Uploaded File: {acc * 100:.2f}%\")\n",
        "\n",
        "# Confusion Matrix\n",
        "# cm = confusion_matrix(y_real_test, y_real_pred)\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "# disp.plot(cmap='Blues')\n",
        "# plt.title(\"Confusion Matrix on Real Test Set\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "3lV3WQ_crxos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mO83dnUtterk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}